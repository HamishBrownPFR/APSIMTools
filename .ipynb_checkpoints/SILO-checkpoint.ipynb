{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esto es un titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the \".nc\" file using netCDF4 library and\n",
    "# store a pointer to it in the \"data\" variable\n",
    "# we assume that the file you want to load is in the same folder\n",
    "# as this .ipynb file\n",
    "\n",
    "data = netCDF4.Dataset('2011.daily_rai.nc', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If I would like to, I could store ALL the arrays for the different keys in the 'variables' dictionary as below (uncomment if you want to play with that). We won't do that now since we are trying to understand what **shape** the data has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lat = data.variables['lat'][:]\n",
    "#lon = data.variables['lon'][:]\n",
    "#time = data.variables['time'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the **shape** of the data we have at hand, begining by looking at the different variables we have available to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are my available dimensions? (the ones that describe the general 'shape' of the data)\n",
    "data.dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are my variables? (the ones actually containing the data)\n",
    "data.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to see which **methods** (functions that *do something*) and **attributes** (as the name indicates, these are mere *properties*, they return a value rather than *performing an action on the data*) are available to me on \"one\" of the dimensions, in this case \"latitude\" we can use the **dir** default method. \n",
    "\n",
    "> **NOTE**: the \"dir\" method is built-in into python, it has nothing to do with netCDF4 or any other imported library. You can use \"dir\" to inspect any kind of python object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the description *https://silo.longpaddock.qld.gov.au/data-products* is giving us about the data?\n",
    "\n",
    "```\n",
    "Gridded daily climate surfaces which have been derived either by splining or kriging the observational data:\n",
    "\n",
    "The grid spans 112°E to 154°E, 10°S to 44°S with resolution 0. 05° latitude by 0.05° longitude (approximately 5 km × 5 km). \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data.variables['lat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's explore the contents of the \"lat\" key inside the \"variables\" dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.variables['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first value\n",
    "data.variables['lat'][0]\n",
    "\n",
    "# last value\n",
    "data.variables['lat'][680]\n",
    "\n",
    "# Total values?\n",
    "len(data.variables['lat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok, let's get into the juicy stuff\n",
    "\n",
    "If we recall from our previous \"data shape\" exploration, we saw this for the \"max temp\" variable: \n",
    "\n",
    "```\n",
    "('max_temp', <class 'netCDF4._netCDF4.Variable'>\n",
    "              int16 max_temp(time, lat, lon)\n",
    "                  _FillValue: -32768\n",
    "                  add_offset: 0.0\n",
    "                  long_name: Maximum temperature\n",
    "                  units: Celsius\n",
    "                  scale_factor: 0.1\n",
    "              unlimited dimensions: time\n",
    "              current shape = (365, 681, 841)\n",
    "              filling on)\n",
    "```\n",
    "\n",
    "In *pythonic terms* this is actually a **class** (*<class 'netCDF4._netCDF4.Variable'>*) but we don't have to worry about that at the moment. Suffice to say that this is an object called **max_temp** that will use the previous variables (*time, lat, lon*) to pinpoint a particular value out of the many. This object is also showing us that its \"curret shape\" (structure), and telling us that we need to pass a **time**, **lat** and **lon** (in that order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.variables['max_temp'][45][234][80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing data for day 45 in latitude 234 (-21.7 degrees) in longitud 80 (116 degrees)\n",
    "data.variables['max_temp'][45][234][80]\n",
    "\n",
    "# How many datapoints are there inside the pair (time=45,lat=234)? \n",
    "# (we know it's going to be 841 but we will use the \"len\" built-in method\n",
    "# that returns the lenght of an object in python)\n",
    "len(data.variables['max_temp'][45][234])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to access multiple data\n",
    "for p in range(len(data.variables['max_temp'][45][234])):\n",
    "    print(((p*0.05)+112), data.variables['max_temp'][45][234][p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype function for obtaining \"a\" value based on a combination of three variables (\"keys\" in python terminology): time, lat, lon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our next examples, we want to make our lives easier by capturing the contents of all the max_temp object inside a variable that we can easily manipulate. By doing this, we avoid having to call `data.variables['max_temp']` **every** time we want to access a datapoint inside \"max_temp\". We can just call `maxtemp` (our newly created variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtemp = data.variables['max_temp'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we need to create our \"mother\" function (template function) that will help us derive multiple different functions by adapting it. \n",
    "Because we need to extract data for the *Tasmania* region only, we first grabbed the 8 (lat,lon) pairs that make up the rectangle where Tasmania fits in. However, the data that we will be accessing **doesn't understand lat and lon**, it only understands **integers** (our lat dimension had 641 elements, which is the result of dividing the range of *lat* and *lon* by the scale (0.05). In other words, each *degree* is divided by 20. We need to capture that range, but *only for Tasmania*. That's why we will use the *arange* method provided to us by **numpy** to create a range of (lat,lon) degrees that span the Tasmania region only (we will also capture the \"time\"): \n",
    "\n",
    "```python\n",
    "lat_range = np.arange(39,44,0.05)\n",
    "lon_range = np.arange(143,150,0.05)\n",
    "t = np.arange(0,365,1)\n",
    "```\n",
    "\n",
    "After doing this, we need to define the function with **def**. The function should accept three parameters (time, lat, lon)\n",
    "\n",
    "> NOTE: the name you give to these parameters doesn't matter, they don't necessarily *need to match* with those found in your dataset. We could have named them (time, latit, longit) and the function would still work. These values are only relevant to the \"function\" itself.\n",
    "\n",
    "```python\n",
    "def get_cdf_values(t,lat,lon):\n",
    "```\n",
    "\n",
    "Now we need to create two new variables that will calculate the actual *slice* within the 841 slices of *lon* and 681 slices of *lat* that a given **real latitude or longitud value** matches up against, for that we will create two new variables:\n",
    "\n",
    "```python\n",
    "detailed_lat = int((lat - 10)/ 0.05)\n",
    "detailed_lon = int((lon - 112)/ 0.05)\n",
    "```\n",
    "\n",
    "The function will, finally, print out the results by simply printing the latitude/longitud values we passed on to it (captured in the \"lat\" and \"lon\" variables of the function) and the actual datapoint for \"max_temp\". To get to the \"max_temp\" value we need to index into the original dataset (remember we captured all the range of values inside the **maxtemp** variable) and pass in the *time, lat, lon* indices. This is what we do when we write `maxtemp[t][detailed_lat][detailed_lon]`\n",
    "\n",
    "The complete function follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_range = np.arange(39,44,0.05)\n",
    "lon_range = np.arange(143,150,0.05)\n",
    "t = np.arange(0,365,1)\n",
    "\n",
    "def get_cdf_values(t,lat,lon):\n",
    "    detailed_lat = int((lat - 10)/ 0.05)\n",
    "    detailed_lon = int((lon - 112)/ 0.05)\n",
    "    print('time:', t, 'lat:', lat, 'lon:', lon, 'value:', maxtemp[t][detailed_lat][detailed_lon])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to get ALL values (uncomment the following lines) \n",
    "'''\n",
    "for day in t:\n",
    "    for lat in lat_range:\n",
    "        for lon in lon_range:\n",
    "            get_cdf_values(day,lat,lon)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a function that will accept two spatial variables (lat, long) and will return each value for all days (time datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_range = np.arange(39,44,0.05)\n",
    "lon_range = np.arange(143,150,0.05)\n",
    "t = np.arange(0,365,1)\n",
    "jday = np.arange(1,366,1)\n",
    "\n",
    "def get_cdf_values_bytime(lat,lon):\n",
    "    detailed_lat = int((lat - 10) / 0.05)\n",
    "    detailed_lon = int((lon - 112) / 0.05)\n",
    "    #print(detailed_lat)\n",
    "    #print(detailed_lon)\n",
    "    values = []\n",
    "    \n",
    "    for day in t:\n",
    "        val = maxtemp[day][detailed_lat][detailed_lon]\n",
    "        val = round(val,1)\n",
    "        values.append(val)\n",
    "        \n",
    "        #print('jday', jday, 'value', val)\n",
    "    \n",
    "    df = pd.DataFrame(values, columns=['Tmax'], index=jday)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int((116 - 112) / 0.05)\n",
    "#int((80 * 0.05) + 112)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = get_cdf_values_bytime(39.05,145.10)\n",
    "df2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('3905-14510.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "real_lat_range = np.arange(39,44,0.05)\n",
    "real_lon_range = np.arange(143,150,0.05)\n",
    "slice_lon_range = [int((x - 112)/ 0.05) for x in real_lon_range]\n",
    "\n",
    "t = np.arange(0,365,1)\n",
    "jday = np.arange(1,366,1)\n",
    "\n",
    "def get_values_FuckYeah_export_csv(t,lat):\n",
    "    detailed_lat = int((lat - 10)/ 0.05)\n",
    "    \n",
    "    data_values = []\n",
    "    lon_values = []\n",
    "    \n",
    "    for lon_slice in slice_lon_range:\n",
    "        # let's retrieve the specific data value first\n",
    "        val = maxtemp[t][detailed_lat][lon_slice]\n",
    "\n",
    "        if type(val) is not numpy.ma.core.MaskedConstant:\n",
    "            val = round(val,1)\n",
    "            # if the value is NOT \"masked\" then we have actually a value\n",
    "            # and we will append it to the data_values list\n",
    "            data_values.append(val)\n",
    "            \n",
    "        else:\n",
    "            # if the value is \"masked\" then it's non-existent\n",
    "            # and we will append a \"None\" instead of a real value\n",
    "            data_values.append(None)\n",
    "        \n",
    "        # let's now append the \"real longitude\" value for this loop iteration\n",
    "        #detailed_lon = int((lon - 112)/ 0.05)\n",
    "        #real_lon = int((lon_slice * 0.05) + 112)\n",
    "        #print(real_lon)\n",
    "        #lon_values.append(real_lon)\n",
    "\n",
    "    # we need to get the total amount of values collected\n",
    "    total_values = len(data_values)\n",
    "    \n",
    "    # let's now create a numpy array containing the \"latitude\" value\n",
    "    # we are pivoting off in this loop iteration. The same value\n",
    "    # should be repeated as many times as \"lon\" values there are (841)\n",
    "    lat_values = np.full(total_values, lat)\n",
    "\n",
    "    # let's do the same as above but for the \"date\" dimension this time\n",
    "    time_values = np.full(total_values, t)\n",
    "\n",
    "    # now we need to fill a PANDAS DataFrame with the lists we've been \n",
    "    # compiling\n",
    "    pandas_dict_of_items = {'Lat': lat_values,\n",
    "                            'Lon': real_lon_range,\n",
    "                            'jday': time_values,\n",
    "                            'Tmax': data_values}\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(pandas_dict_of_items)\n",
    "      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking La Bestia Pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**La Bestia Pop** should create df of 306965 rows each (841 x 365), **but** we are only going limiting this to to the data within the Tasmanian region. Thus, the total rows will be **365 x 141**: the total julian days *by all the points between lon 143 and 150 in 0.05 increments*. What we will do, so that we don't end up with a *super-masive-beast* df, is to export to a csv file each one of those df (i.e. every 306965) rows. Essentially, you will end up with a csv file **per each 0.05 fraction of a latitude degree** or, in other words, **20 files** for each full latitude degree.\n",
    "The expected output that you will see is similar to this: \n",
    "\n",
    "```\n",
    "Writting CSV file Lat-39.0.csv to C:\\Users\\PopBeast\\Documents\\Project-01\n",
    "Writting CSV file Lat-39.05.csv to C:\\Users\\PopBeast\\Documents\\Project-01\n",
    "Writting CSV file Lat-39.099999999999994.csv to C:\\Users\\PopBeast\\Documents\\Project-01\n",
    "Writting CSV file Lat-39.14999999999999.csv to C:\\Users\\PopBeast\\Documents\\Project-01\n",
    "```\n",
    "\n",
    "If you go to your current folder, you should find the files in there, they will be 14MB files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first create an empty df\n",
    "monster_df = pd.DataFrame()\n",
    "\n",
    "# now let's iterate through each \"latitude\" value and, \n",
    "# within this loop, let's create another one that will\n",
    "# iterate through the different \"days\" in the year\n",
    "\n",
    "for lat in lat_range:\n",
    "    for day in t:\n",
    "        temp_df = get_values_FuckYeah_export_csv(day,lat)\n",
    "        monster_df = monster_df.append(temp_df, ignore_index=True)\n",
    "    \n",
    "    # let's build the name of the file based on the value of the \n",
    "    # first row for latitude\n",
    "    csv_name = 'Lat-{}.csv'.format(monster_df['Lat'][0])\n",
    "    \n",
    "    # let's get the current directory so we can let the user\n",
    "    # know where the file is going to get written to\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # return info to user and write df to csv\n",
    "    print(\"Writting CSV file\", csv_name, \"to\", current_dir)\n",
    "    monster_df.to_csv(csv_name)\n",
    "            \n",
    "    # when we get out of the previous loop, we will have a df\n",
    "    # containing 306965 rows, we need to write that to a csv file\n",
    "    # and then \"reset\" the monster_df back to zero.\n",
    "    monster_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_range = np.arange(143,150,0.05)\n",
    "det_range = [int((x - 112)/ 0.05) for x in lon_range]\n",
    "[((x * 0.05) + 112) for x in det_range]\n",
    "len(real_lon_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a dictionary in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ejemplodic = {\"lat\": \"45\", \"lon\": \"56\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if I want to access the \"lat\" key?\n",
    "ejemplodic['lat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a list?\n",
    "example_list = ['zero', 'one', 'two']\n",
    "example_list2 = [1,2,3,4,5]\n",
    "example_list3 = [1,2,3,'four']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
