{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a list of observed files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeatherFilePaths = []\n",
    "mydir = 'C:\\Users\\cflhxb\\Dropbox\\APSIMPotato\\Observed\\SubStorValidationData\\weather'\n",
    "for file in os.listdir(mydir):\n",
    "    if file.endswith('.WTH'):\n",
    "        WeatherFilePaths.append(os.path.join(mydir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a list of data frames to work through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileNames = []\n",
    "WeatherFiles = []\n",
    "Headers = []\n",
    "for File in WeatherFilePaths:\n",
    "    FileNames.append(File.replace('C:\\\\Users\\\\cflhxb\\\\Dropbox\\\\APSIMPotato\\\\Observed\\\\SubStorValidationData\\\\weather\\\\','').replace('.WTH',''))\n",
    "    Headers.append(pd.read_csv(File,sep='\\s+',skiprows=2,nrows=1))\n",
    "    WeatherFiles.append(pd.read_csv(File,sep='\\s+',skiprows=4,converters={'@DATE': lambda x: str(x)}).dropna(how = 'all',axis=1).dropna(how='all'))\n",
    "#put a location column into weather dataframes\n",
    "for w in range(len(WeatherFilePaths)):\n",
    "    WeatherFiles[w].ix[:,'@'] = Headers[w]['@'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse weird substore date into an actual date format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Centuary(Y):\n",
    "    if float(Y) < 20:\n",
    "        return '20'\n",
    "    else:\n",
    "        return '19'\n",
    "count = 0    \n",
    "for w in WeatherFiles:\n",
    "    Y = [str(w.ix[x,'@DATE'])[:2] for x in w.index]\n",
    "    C = [Centuary(x) for x in Y]\n",
    "    Year = [C[x]+Y[x] for x in range(len(Y))]\n",
    "    w.ix[:,'FileName'] = FileNames[count]\n",
    "    w.ix[:,'Year'] = Year\n",
    "    w.ix[:,'DOY'] = [str(w.ix[x,'@DATE'])[2:] for x in w.index]\n",
    "    w.ix[:,'Date'] = [datetime.datetime.strptime(w.Year[x]+'/'+w.DOY[x],'%Y/%j') for x in w.index]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all of the met data into a single data frame for cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnHeaders = []\n",
    "for w in WeatherFiles:\n",
    "    for c in list(w.columns):\n",
    "        ColumnHeaders.append(c)\n",
    "Columns = set(ColumnHeaders)\n",
    "AllMetData = pd.DataFrame(columns=Columns)\n",
    "for w in WeatherFiles:\n",
    "    AllMetData = AllMetData.append(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the met data clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllMetData.drop_duplicates(inplace=True)\n",
    "AllMetData.set_index('FileName',inplace=True)\n",
    "AllMetData.ix[:,'Day'] = [int(AllMetData.ix[x,'DOY']) for x in range(AllMetData.index.size)]\n",
    "AllMetData.replace(to_replace='[A-z]',value='',inplace=True,regex=True)\n",
    "AllMetData.replace(to_replace=-99,value=np.nan,inplace=True)\n",
    "AllMetData.ix[:,'RAIN'] = pd.to_numeric(AllMetData.RAIN)\n",
    "AllMetData.ix[:,'SRAD'] = pd.to_numeric(AllMetData.SRAD)\n",
    "AllMetData.ix[:,'TMAX'] = pd.to_numeric(AllMetData.TMAX)\n",
    "AllMetData.ix[:,'TMIN'] = pd.to_numeric(AllMetData.TMIN)\n",
    "AllMetData.ix[:,'WIND'] = pd.to_numeric(AllMetData.WIND)\n",
    "AllMetData.ix[:,'Tmean'] = (AllMetData.ix[:,'TMAX'] + AllMetData.ix[:,'TMIN'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "APSIMMetData = pd.DataFrame(columns = ['year','day','rain','maxt','mint','radn'],index = AllMetData.index)\n",
    "APSIMMetData.ix[:,'year'] = AllMetData.ix[:,'Year']\n",
    "APSIMMetData.ix[:,'day'] = AllMetData.ix[:,'Day']\n",
    "APSIMMetData.ix[:,'rain'] = AllMetData.ix[:,'RAIN']\n",
    "APSIMMetData.ix[:,'maxt'] = AllMetData.ix[:,'TMAX']\n",
    "APSIMMetData.ix[:,'mint'] = AllMetData.ix[:,'TMIN']\n",
    "APSIMMetData.ix[:,'radn'] = AllMetData.ix[:,'SRAD']\n",
    "APSIMMetData.dropna(subset=['rain','maxt','mint','radn'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the header information into a tidy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnHeaders = []\n",
    "count = 0\n",
    "for h in Headers:\n",
    "    h.ix[0,'FileName'] = FileNames[count]\n",
    "    count += 1\n",
    "for h in Headers:\n",
    "    for c in list(h.columns):\n",
    "        ColumnHeaders.append(c)        \n",
    "Columns = set(ColumnHeaders)\n",
    "AllHeaders = pd.DataFrame(columns=Columns)\n",
    "for h in Headers:\n",
    "    AllHeaders = AllHeaders.append(h)\n",
    "AllHeaders.drop_duplicates(inplace=True)\n",
    "AllHeaders.set_index('FileName',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make files for each location with header data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in AllHeaders.index:\n",
    "    TopLine = pd.DataFrame(data = ['[weather.met.weather]'])\n",
    "    TopLine.ix[1,0] = 'Site = ' + file\n",
    "    TopLine.ix[2,0] = 'Latitude=' + str(AllHeaders.ix[file,'INSI'])\n",
    "    TopLine.ix[3,0] = 'Longitude=' + str(AllHeaders.ix[file,'LAT'])\n",
    "    TopLine.ix[4,0] = 'tav=' +  str(AllMetData.ix[file,'Tmean'].mean())\n",
    "    Fpctle = np.percentile(AllMetData.ix[file,'Tmean'].dropna().values,5)\n",
    "    NFpctle = np.percentile(AllMetData.ix[file,'Tmean'].dropna().values,95)\n",
    "    TopLine.ix[5,0] = 'amp=' + str(NFpctle - Fpctle)\n",
    "    TopLine.ix[6,0] = 'year day rain maxt mint radn'\n",
    "    TopLine.ix[7,0] = '() () (mm) (oC) (oC) (MJ/m2/d)'\n",
    "    TopLine.to_csv('C:\\Users\\cflhxb\\Dropbox\\APSIMPotato\\MET files\\\\' +file+ '.met',\n",
    "                   header=False,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the met data into each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in AllHeaders.index:\n",
    "    MetData = APSIMMetData.ix[file,:]\n",
    "    MetData.to_csv('C:\\Users\\cflhxb\\Dropbox\\APSIMPotato\\MET files\\\\' +file+ '.met',\n",
    "                   header=False,index=False,mode='a',sep=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
